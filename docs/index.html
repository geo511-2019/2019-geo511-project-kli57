<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Ke Li" />


<title>Monitoring vegetation change for over 30 years</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/simplex.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="styles.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 41px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 46px;
  margin-top: -46px;
}
.section h2 {
  padding-top: 46px;
  margin-top: -46px;
}
.section h3 {
  padding-top: 46px;
  margin-top: -46px;
}
.section h4 {
  padding-top: 46px;
  margin-top: -46px;
}
.section h5 {
  padding-top: 46px;
  margin-top: -46px;
}
.section h6 {
  padding-top: 46px;
  margin-top: -46px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-inverse  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">R Data Science Final Project</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Monitoring vegetation change for over 30 years</h1>
<h4 class="author">Ke Li</h4>

</div>


<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>Knowing change of vegetation plays a significant role in city management and environment issue. Image classification combining with remote sensing satellite data provides an promosing way to display mapping of vegetation change. However, assigning one class in one pixel which has 30 meter sptial resolution always accompany with some classification mistake, citing the reason that one pixel always mixed with different classes. In this project, I intend to use multiple endmember spectral mixture analysis to acquire proportion of each class for per-pixel level. Moreover, to understand change of vegetation, supervised classification method will be used in unmixing image to get the trend of vegetation change.</p>
</div>
<div id="materials-and-methods" class="section level1">
<h1>Materials and methods</h1>
<p>Since vegetation change is focus on change between 30 years, Landsat 8 OLI and Landsat 5 August images will be used in this project to collecting enough pure pixels of each class and finding training samples of vegetation increase, vegetation decrease and vegetation no change class.There are three main steps in this project:</p>
<ol style="list-style-type: decimal">
<li><p>The pure pixel of vegetation, urban area, soil and water was collected in 1988, 1998, 2008 and 2018 using ROI method in ENVI. The location of each sample were recorded and export as .shp file. The mean value of each extract satellite value of each class is considered as the spectrum of pure pixel.</p></li>
<li><p>Acquiring fraction of each class within one-pixel level after performing multiple endmemer spectral mixture analysis, the change images between 1988 and 1998, 1998 and 2008, 2008 and 2018 were acquired using subtraction method. Therefore, each pixel contains change information about vegetation, urban, soil and water.</p></li>
<li><p>ROI method in ENVI in each change year was used in collection change pixel about vegetation increase, vegetation decrease, vegetation no change and other change. Change points of vegetation increase, vegetation decrease, vegetation no change are collected about each 300 points, the number of point of other change points are 150 points. I use 70% samples to train maximum likelihood classification model, and 30% samples to test classification method.</p></li>
</ol>
<p>The packages used in this project are listed below:</p>
<pre class="r"><code>library(googledrive)
library(raster)
library(rgdal)
library(sf)
library(foreach)
library(doParallel)
library(tidyverse)
library(RStoolbox)</code></pre>
<p>The post image is Landsat8OLI image I used in 2018.</p>
<p><img src="index_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<div id="unmixing-and-classification" class="section level2">
<h2>Unmixing and classification</h2>
<p>After extract pure pixel satellite value, the value of endmember of each class were averaged as the value of each pure class.</p>
<pre class="r"><code>extract_water_2018=raster::extract(img2018,img2018_water)
extract_veg_2018=raster::extract(img2018,img2018_veg)
extract_urban_2018=raster::extract(img2018,img2018_urban)
extract_soil_2018=raster::extract(img2018,img2018_soil)

water_2018&lt;-colMeans(foreach(i=1:NROW(extract_water_2018),.combine = &quot;rbind&quot;)%do%
                       unlist(extract_water_2018[[i]]))
soil_2018&lt;-colMeans(foreach(i=1:NROW(extract_soil_2018),.combine = &quot;rbind&quot;)%do%
                      unlist(extract_soil_2018[[i]]))
urban_2018&lt;-colMeans(foreach(i=1:NROW(extract_urban_2018),.combine = &quot;rbind&quot;)%do%
                       unlist(extract_urban_2018[[i]]))
veg_2018&lt;-colMeans(foreach(i=1:NROW(extract_veg_2018),.combine = &quot;rbind&quot;)%do%
                     unlist(extract_veg_2018[[i]]))

end_2018&lt;-rbind(water_2018,soil_2018,urban_2018,veg_2018)
rownames(end_2018)&lt;-c(&#39;water&#39;,&quot;soil&quot;,&#39;urban&#39;,&#39;veg&#39;)

end_2018</code></pre>
<pre><code>##       ImageBuffalo2017.2019.1 ImageBuffalo2017.2019.2 ImageBuffalo2017.2019.3
## water                439.1800                494.1145                315.8969
## soil                 567.6534                897.0720                935.8900
## urban               1185.8796               1507.8604               1650.2978
## veg                  225.7322                461.0819                254.7379
##       ImageBuffalo2017.2019.4 ImageBuffalo2017.2019.5 ImageBuffalo2017.2019.6
## water                330.4039                196.6204                155.0606
## soil                3259.7874               2437.1682               1682.1300
## urban               2268.0946               2242.4622               1832.0127
## veg                 3700.2296               1464.5617                599.7139</code></pre>
<p>Multiple Endmember Spectral Mixture Anslysis was used in acquiring fraction of each class. By allowing various endmember for per-pixel level, each pixel can be accounted for fraction of each class. In this study, MESMA acquired five imgae: soil fraction, vegetation fraction, urban fracion and water fraction and RMSE. Considering the change fraction of four class, the first four layer were extracted.</p>
<pre class="r"><code>unmix2018 &lt;- mesma(img2018,end_2018, method = &quot;NNLS&quot;)
unmix2008 &lt;- mesma(img2008,end_2008, method = &quot;NNLS&quot;)
change_2018&lt;- (unmix2018-unmix2008)[[1:4]]</code></pre>
<p>The collected shapefile data is not spatialpoint data frame, so I create data frame using imported data point and connect to the longitude and latitude. And Maximum likelihood to classify the four class: vegetation increase, vegetation decrease, vegetation nochange and other.</p>
<pre class="r"><code>class_2018=data.frame(class=c(rep(&#39;vegincrease2018&#39;,length(vegincrease2018$ID)),
                              rep(&#39;vegdecrease2018&#39;,length(vegdecrease2018$ID)),
                              rep(&#39;vegnochange2018&#39;,length(vegnochange2018$ID)),
                              rep(&#39;other2018&#39;,length(other2018$ID))))
vegin_lonlat2018&lt;-as.data.frame(st_coordinates(vegincrease2018$geometry))
vegde_lonlat2018&lt;-as.data.frame(st_coordinates(vegdecrease2018$geometry))
vegno_lonlat2018&lt;-as.data.frame(st_coordinates(vegnochange2018$geometry))
other_lonlat2018&lt;-as.data.frame(st_coordinates(other2018$geometry))

lon_lat_2018&lt;-rbind(vegin_lonlat2018,vegde_lonlat2018,vegno_lonlat2018,other_lonlat2018)
training2018&lt;-SpatialPointsDataFrame(lon_lat_2018,class_2018)
crs(training2018)&lt;-crs(change_2018)
mlh_2018&lt;-superClass(change_2018, trainData = training2018, responseCol = &quot;class&quot;, 
                     model=&quot;mlc&quot;, tuneLength = 1, trainPartition = 0.7)</code></pre>
</div>
</div>
<div id="results" class="section level1">
<h1>Results</h1>
<pre><code>##                  Reference
## Prediction        other1988 vegdecrease1988 vegincrease1988 vegnochange1988
##   other1988              43               0               5               2
##   vegdecrease1988         2              92               0               0
##   vegincrease1988         0               1              70               2
##   vegnochange1988         0               0               0              85</code></pre>
<pre><code>##       Accuracy          Kappa  AccuracyLower  AccuracyUpper   AccuracyNull 
##   9.602649e-01   9.460489e-01   9.316200e-01   9.793025e-01   3.079470e-01 
## AccuracyPValue  McnemarPValue 
##  5.387037e-130            NaN</code></pre>
<pre><code>##                  Reference
## Prediction        other2008 vegdecrease2008 vegincrease2008 vegnochange2008
##   other2008              45               0               0               2
##   vegdecrease2008         0              84               0               0
##   vegincrease2008         0               0              52               0
##   vegnochange2008         0               0               0              86</code></pre>
<pre><code>##       Accuracy          Kappa  AccuracyLower  AccuracyUpper   AccuracyNull 
##   9.925651e-01   9.898333e-01   9.734020e-01   9.990983e-01   3.271375e-01 
## AccuracyPValue  McnemarPValue 
##  4.439153e-126            NaN</code></pre>
<pre><code>##                  Reference
## Prediction        other2018 vegdecrease2018 vegincrease2018 vegnochange2018
##   other2018              42               0               1               0
##   vegdecrease2018         0              86               0               1
##   vegincrease2018         0               0              56               1
##   vegnochange2018         0               0               0              85</code></pre>
<pre><code>##       Accuracy          Kappa  AccuracyLower  AccuracyUpper   AccuracyNull 
##   9.889706e-01   9.849034e-01   9.681075e-01   9.977197e-01   3.198529e-01 
## AccuracyPValue  McnemarPValue 
##  7.119905e-128            NaN</code></pre>
<p>According to the confusion matrix of three change images, we can see that the classification accuracy for maximum likelihood method is higher.</p>
<p><img src="index_files/figure-html/unnamed-chunk-7-1.png" width="864" /><img src="index_files/figure-html/unnamed-chunk-7-2.png" width="864" /></p>
<pre class="r"><code>fre_bind</code></pre>
<pre><code>##              1998  2008  2018
## vegdecrease  2918  3444  2177
## vegincrease  2968  5148  3510
## vegnochange 20076 29501 53393</code></pre>
</div>
<div id="conclusions" class="section level1">
<h1>Conclusions</h1>
<p>This study acquires fraction of each class for per-pixel level in 1988, 1998, 2008 and 2018, and use maximum likelihood classifier to monitor the change of vegetation over 30 years. The classification accuracy of change image between 1998 and 1988, 2008 and 1998,2008 and 2018 have higher accuracy from the testing data. From the vegetation trend for three chang image, the vegetation increase is higher than the vegetation decrease. The area of vegetation no change in 2018 is higher than 2008 and 1998. All in all, the coverage of vegetation is increasing and expand over years.</p>
</div>
<div id="references" class="section level1">
<h1>References</h1>
<p>Rogan, John, Janet Franklin, and Dar A. Roberts. “A comparison of methods for monitoring multitemporal vegetation change using Thematic Mapper imagery.” Remote Sensing of Environment 80.1 (2002): 143-156.</p>
</div>

<!-- give the footer some space -->
<br/>
<br/>

<footer id="site-footer">
  <div id="footer1">
  This website is a project for Adam Wilson's <a href="https://wilsonlab.io/GEO511"><i> Spatial Data Science (GEO511) </i></a>Course at the University at Buffalo
  </div>
  <div id="footer2">
  <a rel="license" property="http://creativecommons.org/ns#license"
  href="http://creativecommons.org/licenses/by/4.0/" ><img src="img/cc-by.svg" alt="cc-by"/></a> 
  </div>
</footer>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>


</body>
</html>
